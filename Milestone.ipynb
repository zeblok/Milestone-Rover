{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blazingsql import BlazingContext\n",
    "import pandas as pd\n",
    "\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.s3('milestone',\n",
    "     bucket_name='datalake',\n",
    "     access_key_id='epapenhausen',\n",
    "     secret_key='5d96af203bf43b74a93765dc',\n",
    "     endpoint_override=\"http://130.245.177.209:9000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add U-Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('u100', 's3://milestone/epapenhausen/Milestone/pdavies/u100.csv')\n",
    "bc.create_table('u101', 's3://milestone/epapenhausen/Milestone/pdavies/u101.csv')\n",
    "bc.create_table('u104', 's3://milestone/epapenhausen/Milestone/pdavies/u104.csv')\n",
    "bc.create_table('u200', 's3://milestone/epapenhausen/Milestone/pdavies/u200.csv')\n",
    "bc.create_table('u175', 's3://milestone/epapenhausen/Milestone/pdavies/u175.csv')\n",
    "bc.create_table('u141', 's3://milestone/epapenhausen/Milestone/pdavies/u141.csv')\n",
    "bc.create_table('u108', 's3://milestone/epapenhausen/Milestone/pdavies/u108.csv')\n",
    "bc.create_table('u178', 's3://milestone/epapenhausen/Milestone/pdavies/u178.csv')\n",
    "bc.create_table('u280', 's3://milestone/epapenhausen/Milestone/pdavies/u280.csv')\n",
    "bc.create_table('u210', 's3://milestone/epapenhausen/Milestone/pdavies/u210.csv')\n",
    "bc.create_table('u780', 's3://milestone/epapenhausen/Milestone/pdavies/u780_NAV-Movement.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add L-Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('l220', 's3://milestone/epapenhausen/Milestone/pdavies/l220.csv')\n",
    "bc.create_table('l222', 's3://milestone/epapenhausen/Milestone/pdavies/l222.csv')\n",
    "bc.create_table('l225', 's3://milestone/epapenhausen/Milestone/pdavies/l225.csv')\n",
    "bc.create_table('l235', 's3://milestone/epapenhausen/Milestone/pdavies/l235.csv')\n",
    "bc.create_table('l295', 's3://milestone/epapenhausen/Milestone/pdavies/l295.csv')\n",
    "bc.create_table('l315', 's3://milestone/epapenhausen/Milestone/pdavies/l315.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add P-Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('p200', 's3://milestone/epapenhausen/Milestone/pdavies/p200.csv')\n",
    "bc.create_table('p201', 's3://milestone/epapenhausen/Milestone/pdavies/p201.csv')\n",
    "bc.create_table('p202', 's3://milestone/epapenhausen/Milestone/pdavies/p202.csv')\n",
    "bc.create_table('p203', 's3://milestone/epapenhausen/Milestone/pdavies/p203.txt')\n",
    "bc.create_table('p204', 's3://milestone/epapenhausen/Milestone/pdavies/p204.csv')\n",
    "bc.create_table('p205', 's3://milestone/epapenhausen/Milestone/pdavies/p205.csv')\n",
    "bc.create_table('p206', 's3://milestone/epapenhausen/Milestone/pdavies/p206.csv')\n",
    "bc.create_table('p207', 's3://milestone/epapenhausen/Milestone/pdavies/p207.csv')\n",
    "bc.create_table('p208', 's3://milestone/epapenhausen/Milestone/pdavies/p208.csv')\n",
    "bc.create_table('p209', 's3://milestone/epapenhausen/Milestone/pdavies/p209.csv')\n",
    "bc.create_table('p210', 's3://milestone/epapenhausen/Milestone/pdavies/p210.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u100 = bc.sql(\"select * from u100\")\n",
    "u101 = bc.sql(\"select * from u101\")\n",
    "u104 = bc.sql(\"select * from u104\")\n",
    "u200 = bc.sql(\"select * from u200\")\n",
    "u175 = bc.sql(\"select * from u175\")\n",
    "u141 = bc.sql(\"select * from u141\")\n",
    "u108 = bc.sql(\"select * from u108\")\n",
    "u178 = bc.sql(\"select * from u178\")\n",
    "u280 = bc.sql(\"select * from u280\")\n",
    "u210 = bc.sql(\"select * from u210\")\n",
    "u780 = bc.sql(\"select * from u780\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p200 = bc.sql(\"select * from p200\")\n",
    "p201 = bc.sql(\"select * from p201\")\n",
    "p202 = bc.sql(\"select * from p202\")\n",
    "p203 = bc.sql(\"select * from p203\")\n",
    "p204 = bc.sql(\"select * from p204\")\n",
    "p205 = bc.sql(\"select * from p205\")\n",
    "p206 = bc.sql(\"select * from p206\")\n",
    "p207 = bc.sql(\"select * from p207\")\n",
    "p208 = bc.sql(\"select * from p208\")\n",
    "p209 = bc.sql(\"select * from p209\")\n",
    "p210 = bc.sql(\"select * from p210\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l220 = bc.sql(\"select * from l220\")\n",
    "l222 = bc.sql(\"select * from l222\")\n",
    "l225 = bc.sql(\"select * from l225\")\n",
    "l235 = bc.sql(\"select * from l235\")\n",
    "l295 = bc.sql(\"select * from l295\")\n",
    "l315 = bc.sql(\"select * from l315\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compound unique keys: (Entity Code, Effective Date, Run_ID, Price Run)\n",
    "def sanitize(table, run_type='Oversight', status=None):\n",
    "    filt = (table['price_run_type']==run_type)\n",
    "    if status is not None:\n",
    "        filt = filt&(table['p_status']==status)\n",
    "    \n",
    "    table_san = table[filt]\n",
    "    drop = [c for c in table_san.columns if table_san[c].nunique() <= 1]+['pcontrol_id']\n",
    "    return table_san.drop(drop, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u101_san = sanitize(u101, status='V')\n",
    "u100_san = sanitize(u100, status='V')\n",
    "\n",
    "a01 = sanitize(p200)\n",
    "a02 = sanitize(p201)\n",
    "a03 = sanitize(p202)\n",
    "a04 = sanitize(p203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_summary(raw, keys, data_name):\n",
    "    ''' Computes summary for categorical attributes using \"keys\" as a primary key. '''\n",
    "    categories = [c for c in raw.columns[raw.dtypes==object] if c not in keys]\n",
    "    cat_data = {str(cat)+'_'+str(level): [] for cat in categories for level in raw[cat].unique()}\n",
    "\n",
    "    data = {**{k: [] for k in keys}, 'num_'+data_name: [], **cat_data}    \n",
    "    for k, g in raw.groupby(keys): #'pcontrol_code'):\n",
    "        n = g.shape[0]\n",
    "        base_value = g.base_mv_close.sum()\n",
    "        \n",
    "        for cd in cat_data:\n",
    "            data[cd].append(0)\n",
    "                    \n",
    "        for cat in categories:        \n",
    "            #cat_vc = g[cat].value_counts()\n",
    "            cat_vc = g.groupby(cat)['base_mv_close'].sum()\n",
    "            for level, value in cat_vc.to_pandas().iteritems():\n",
    "                index = str(cat)+'_'+str(level)                     \n",
    "                data[index][-1] = value / base_value\n",
    "                                \n",
    "        for i, ky in enumerate(keys):\n",
    "            data[ky].append(k[i])\n",
    "        \n",
    "        data['num_'+data_name].append(n)          \n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['pcontrol_code', 'effective_date']\n",
    "u100_data = nested_summary(u100_san, keys, 'assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "primary_key = ['pcontrol_code', 'effective_date']\n",
    "product_data = pd.merge(a01.to_pandas(), u101_san.to_pandas(), how='left', left_on=primary_key, right_on=primary_key)\n",
    "product_data = pd.merge(product_data, u100_data, how='left', left_on=primary_key, right_on=primary_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify columns to be dropped as they are not relevant to the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date columns not relevant to the analysis\n",
    "datedrop = ['last_updated_date_x', 'last_updated_date_y', 'run_date_and_time', 'value_date', 'effective_date']\n",
    "\n",
    "# since we will be using the max_tol_lvl to construct the target variable, drop variables that could cause leakage\n",
    "leakdrop = ['max_tol_lvl', 'holding_max_tol_lvl']\n",
    "\n",
    "# drop columns indicating the data source\n",
    "sourcedrop = [c for c in product_data.columns if '_source_' in c]\n",
    "\n",
    "# drop columns relating to internal pcontrol flags\n",
    "pcontroldrop = ['integrity_value', 'pcontrol_code'] + [c for c in product_data.columns if 'batch' in c] + [c for c in product_data.columns if c[:2] == 'c_'] + [c for c in product_data.columns if 'updated_by' in c]\n",
    "\n",
    "drop = datedrop + leakdrop + sourcedrop + pcontroldrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Year, Month, and Day from the date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "value_year = product_data['value_date'].apply(lambda x: float(str(x)[:4]) if not np.isnan(x) else x)\n",
    "value_month = product_data['value_date'].apply(lambda x: float(str(x)[4:6]) if not np.isnan(x) else x)\n",
    "value_day = product_data['value_date'].apply(lambda x: float(str(x)[6:]) if not np.isnan(x) else x)\n",
    "\n",
    "eff_year = product_data['effective_date'].apply(lambda x: float(str(x)[:4]) if not np.isnan(x) else x)\n",
    "eff_month = product_data['effective_date'].apply(lambda x: float(str(x)[4:6]) if not np.isnan(x) else x)\n",
    "eff_day = product_data['effective_date'].apply(lambda x: float(str(x)[6:]) if not np.isnan(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data['value_date_year'] = value_year\n",
    "product_data['value_date_month'] = value_month\n",
    "product_data['value_date_day'] = value_day\n",
    "\n",
    "product_data['effective_date_year'] = eff_year\n",
    "product_data['effective_date_month'] = eff_month\n",
    "product_data['effective_date_day'] = eff_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data['pcontrol_code'].unique()\n",
    "\n",
    "fund_names = u100_san['pcontrol_code'].unique()\n",
    "product_data['fund'] = product_data['pcontrol_code'].apply(lambda x: next((f for f in fund_names if f in x), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A01 Product Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_context_map.pattern_miner as pm\n",
    "\n",
    "# A tolerance breach has occured if max_tol_lvl > 0\n",
    "data = product_data.copy()\n",
    "data['breached'] = (data['max_tol_lvl']>0).astype(int)\n",
    "\n",
    "# drop the occurrences where the previous nav amount is 0\n",
    "data = data[data['net_nav_amount_prev']!=0]\n",
    "data.drop(drop, axis=1, inplace=True)\n",
    "\n",
    "target = 'breached'\n",
    "out = pm.DataContextMap(data, target, max_pattern=1000, max_depth=3, mine_type='binary', holdout=0)\n",
    "out.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
